{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. wsi 경로 list로 만듦\n",
    "2. wsi 읽음\n",
    "3. patch로 쪼갬\n",
    "4. patch들 h5로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from wsi_core.WholeSlideImage import WholeSlideImage\n",
    "from wsi_core.wsi_utils import StitchCoords\n",
    "from wsi_core.batch_process_utils import initialize_df\n",
    "# other imports\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitching(file_path, wsi_object, downscale = 64):\n",
    "    start = time.time()\n",
    "    heatmap = StitchCoords(file_path, wsi_object, downscale=downscale, bg_color=(0,0,0), alpha=-1, draw_grid=False)\n",
    "    total_time = time.time() - start\n",
    "    \n",
    "    return heatmap, total_time\n",
    "\n",
    "def segment(WSI_object, seg_params = None, filter_params = None, mask_file = None):\n",
    "    ### Start Seg Timer\n",
    "    start_time = time.time()\n",
    "    # Use segmentation file\n",
    "    if mask_file is not None:\n",
    "        WSI_object.initSegmentation(mask_file)\n",
    "    # Segment\t\n",
    "    else:\n",
    "        WSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
    "\n",
    "    ### Stop Seg Timers\n",
    "    seg_time_elapsed = time.time() - start_time   \n",
    "    return WSI_object, seg_time_elapsed\n",
    "\n",
    "def patching(WSI_object, patient_id, **kwargs):\n",
    "    ### Start Patch Timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Patch\n",
    "    file_path = WSI_object.process_contours(patient_id, **kwargs)\n",
    "\n",
    "\n",
    "    ### Stop Patch Timer\n",
    "    patch_time_elapsed = time.time() - start_time\n",
    "    return file_path, patch_time_elapsed\n",
    "\n",
    "\n",
    "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
    "                patch_size = 256, step_size = 256, \n",
    "                seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "                'keep_ids': 'none', 'exclude_ids': 'none'},\n",
    "                filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8}, \n",
    "                vis_params = {'vis_level': -1, 'line_thickness': 500},\n",
    "                patch_params = {'use_padding': True, 'contour_fn': 'four_pt'},\n",
    "                patch_level = 0,\n",
    "                use_default_params = False, \n",
    "                seg = False, save_mask = True, \n",
    "                stitch= False, \n",
    "                patch = False, auto_skip=True, process_list = None):\n",
    "    \n",
    "\n",
    "\n",
    "    folders = sorted(os.listdir(source))\n",
    "    slides = []\n",
    "    for folder in folders:\n",
    "        files = os.listdir(os.path.join(source, folder))\n",
    "        for file in files:\n",
    "            if file.endswith('svs'):\n",
    "                slides.append(os.path.join(folder, file))\n",
    "    #slides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
    "\n",
    "    if process_list is None:\n",
    "        df = initialize_df(slides, seg_params, filter_params, vis_params, patch_params)\n",
    "    \n",
    "    else:\n",
    "        df = pd.read_csv(process_list)\n",
    "        df = initialize_df(df, seg_params, filter_params, vis_params, patch_params)\n",
    "\n",
    "    mask = df['process'] == 1\n",
    "    process_stack = df[mask]\n",
    "\n",
    "    total = len(process_stack)\n",
    "\n",
    "    legacy_support = 'a' in df.keys()\n",
    "    if legacy_support:\n",
    "        print('detected legacy segmentation csv file, legacy support enabled')\n",
    "        df = df.assign(**{'a_t': np.full((len(df)), int(filter_params['a_t']), dtype=np.uint32),\n",
    "        'a_h': np.full((len(df)), int(filter_params['a_h']), dtype=np.uint32),\n",
    "        'max_n_holes': np.full((len(df)), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
    "        'line_thickness': np.full((len(df)), int(vis_params['line_thickness']), dtype=np.uint32),\n",
    "        'contour_fn': np.full((len(df)), patch_params['contour_fn'])})\n",
    "\n",
    "    seg_times = 0.\n",
    "    patch_times = 0.\n",
    "    stitch_times = 0.\n",
    "\n",
    "    ###### patching start#######\n",
    "    for i in range(total):\n",
    "        df.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "        idx = process_stack.index[i]\n",
    "        slide = process_stack.loc[idx, 'slide_id']\n",
    "        print(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
    "        print('processing {}'.format(slide))\n",
    "        \n",
    "        df.loc[idx, 'process'] = 0\n",
    "        slide_id, _ = os.path.splitext(slide)\n",
    "\n",
    "        if auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
    "            print('{} already exist in destination location, skipped'.format(slide_id))\n",
    "            df.loc[idx, 'status'] = 'already_exist'\n",
    "            continue\n",
    "\n",
    "        # Inialize WSI\n",
    "        full_path = os.path.join(source, slide)\n",
    "        WSI_object = WholeSlideImage(full_path)\n",
    "\n",
    "        if use_default_params:\n",
    "            current_vis_params = vis_params.copy()\n",
    "            current_filter_params = filter_params.copy()\n",
    "            current_seg_params = seg_params.copy()\n",
    "            current_patch_params = patch_params.copy()\n",
    "            \n",
    "        else:\n",
    "            current_vis_params = {}\n",
    "            current_filter_params = {}\n",
    "            current_seg_params = {}\n",
    "            current_patch_params = {}\n",
    "\n",
    "\n",
    "            for key in vis_params.keys():\n",
    "                if legacy_support and key == 'vis_level':\n",
    "                    df.loc[idx, key] = -1\n",
    "                current_vis_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "            for key in filter_params.keys():\n",
    "                if legacy_support and key == 'a_t':\n",
    "                    old_area = df.loc[idx, 'a']\n",
    "                    seg_level = df.loc[idx, 'seg_level']\n",
    "                    scale = WSI_object.level_downsamples[seg_level]\n",
    "                    adjusted_area = int(old_area * (scale[0] * scale[1]) / (512 * 512))\n",
    "                    current_filter_params.update({key: adjusted_area})\n",
    "                    df.loc[idx, key] = adjusted_area\n",
    "                current_filter_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "            for key in seg_params.keys():\n",
    "                if legacy_support and key == 'seg_level':\n",
    "                    df.loc[idx, key] = -1\n",
    "                current_seg_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "            for key in patch_params.keys():\n",
    "                current_patch_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "        if current_vis_params['vis_level'] < 0:\n",
    "            if len(WSI_object.level_dim) == 1:\n",
    "                current_vis_params['vis_level'] = 0\n",
    "            \n",
    "            else:\t\n",
    "                wsi = WSI_object.getOpenSlide()\n",
    "                best_level = wsi.get_best_level_for_downsample(64)\n",
    "                current_vis_params['vis_level'] = best_level\n",
    "\n",
    "        if current_seg_params['seg_level'] < 0:\n",
    "            if len(WSI_object.level_dim) == 1:\n",
    "                current_seg_params['seg_level'] = 0\n",
    "            \n",
    "            else:\n",
    "                wsi = WSI_object.getOpenSlide()\n",
    "                best_level = wsi.get_best_level_for_downsample(64)\n",
    "                current_seg_params['seg_level'] = best_level\n",
    "\n",
    "        keep_ids = str(current_seg_params['keep_ids'])\n",
    "        if keep_ids != 'none' and len(keep_ids) > 0:\n",
    "            str_ids = current_seg_params['keep_ids']\n",
    "            current_seg_params['keep_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "        else:\n",
    "            current_seg_params['keep_ids'] = []\n",
    "\n",
    "        exclude_ids = str(current_seg_params['exclude_ids'])\n",
    "        if exclude_ids != 'none' and len(exclude_ids) > 0:\n",
    "            str_ids = current_seg_params['exclude_ids']\n",
    "            current_seg_params['exclude_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "        else:\n",
    "            current_seg_params['exclude_ids'] = []\n",
    "\n",
    "        w, h = WSI_object.level_dim[current_seg_params['seg_level']] \n",
    "        if w * h > 1e8:\n",
    "            print('level_dim {} x {} is likely too large for successful segmentation, aborting'.format(w, h))\n",
    "            df.loc[idx, 'status'] = 'failed_seg'\n",
    "            continue\n",
    "\n",
    "        df.loc[idx, 'vis_level'] = current_vis_params['vis_level']\n",
    "        df.loc[idx, 'seg_level'] = current_seg_params['seg_level']\n",
    "\n",
    "\n",
    "        seg_time_elapsed = -1\n",
    "        if seg:\n",
    "            WSI_object, seg_time_elapsed = segment(WSI_object, current_seg_params, current_filter_params)\n",
    "            if len(WSI_object.contours_tissue)==0:\n",
    "                print('failed to extract contours')\n",
    "                df.loc[idx, 'status'] = 'failed_seg'\n",
    "                continue\n",
    "\n",
    "        if save_mask:\n",
    "            mask = WSI_object.visWSI(**current_vis_params)\n",
    "            patient_id, wsi_id = slide_id.split('/')\n",
    "            os.makedirs(os.path.join(mask_save_dir, patient_id), exist_ok=True)\n",
    "            mask_path = os.path.join(mask_save_dir, patient_id, wsi_id+'.jpg')\n",
    "            mask.save(mask_path)\n",
    "\n",
    "        patch_time_elapsed = -1 # Default time\n",
    "        if patch:\n",
    "            patient_id, wsi_id = slide_id.split('/')\n",
    "            os.makedirs(os.path.join(patch_save_dir, patient_id), exist_ok=True)\n",
    "            current_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n",
    "                                        'save_path': patch_save_dir})\n",
    "            file_path, patch_time_elapsed = patching(WSI_object = WSI_object,  patient_id=patient_id, **current_patch_params,)\n",
    "        \n",
    "        stitch_time_elapsed = -1\n",
    "        if stitch:\n",
    "            file_path = os.path.join(patch_save_dir, slide_id+'.h5')\n",
    "            if os.path.isfile(file_path):\n",
    "                heatmap, stitch_time_elapsed = stitching(file_path, WSI_object, downscale=64)\n",
    "                patient_id, wsi_id = slide_id.split('/')\n",
    "                os.makedirs(os.path.join(stitch_save_dir, patient_id), exist_ok=True)\n",
    "                stitch_path = os.path.join(stitch_save_dir, patient_id, wsi_id+'.jpg')\n",
    "                heatmap.save(stitch_path)\n",
    "\n",
    "        print(\"segmentation took {} seconds\".format(seg_time_elapsed))\n",
    "        print(\"patching took {} seconds\".format(patch_time_elapsed))\n",
    "        print(\"stitching took {} seconds\".format(stitch_time_elapsed))\n",
    "        df.loc[idx, 'status'] = 'processed'\n",
    "\n",
    "        seg_times += seg_time_elapsed\n",
    "        patch_times += patch_time_elapsed\n",
    "        stitch_times += stitch_time_elapsed\n",
    "\n",
    "    seg_times /= total\n",
    "    patch_times /= total\n",
    "    stitch_times /= total\n",
    "\n",
    "    df.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "    print(\"average segmentation time in s per slide: {}\".format(seg_times))\n",
    "    print(\"average patching time in s per slide: {}\".format(patch_times))\n",
    "    print(\"average stiching time in s per slide: {}\".format(stitch_times))\n",
    "        \n",
    "    return seg_times, patch_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "step_size = 256\n",
    "patch_size = 256\n",
    "patch = True\n",
    "seg = True\n",
    "stitch = True\n",
    "no_auto_skip = True\n",
    "preset = None\n",
    "patch_level = None\n",
    "save_dir = '/shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/'\n",
    "source = '/shared/j.jang/pathai/data/TCGA-lung/'\n",
    "process_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  /shared/j.jang/pathai/data/TCGA-lung/\n",
      "patch_save_dir:  /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/patches\n",
      "mask_save_dir:  /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/masks\n",
      "stitch_save_dir:  /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/stitches\n",
      "source : /shared/j.jang/pathai/data/TCGA-lung/\n",
      "save_dir : /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/\n",
      "patch_save_dir : /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/patches\n",
      "mask_save_dir : /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/masks\n",
      "stitch_save_dir : /shared/js.yun/data/CLAM_data/TCGA-lung-h5-patches/stitches\n",
      "\n",
      " {'seg_params': {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False, 'keep_ids': 'none', 'exclude_ids': 'none'}, 'filter_params': {'a_t': 100, 'a_h': 16, 'max_n_holes': 8}, 'patch_params': {'use_padding': True, 'contour_fn': 'four_pt'}, 'vis_params': {'vis_level': -1, 'line_thickness': 250}} \n",
      "\n",
      "\n",
      "\n",
      "progress: 0.00, 0/1053\n",
      "processing 004d8238-0a74-40bd-9547-f48a2086c416/TCGA-75-7030-01Z-00-DX1.5DDF24B5-00D1-4418-A067-A9B609E15314.svs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating patches for:  TCGA-75-7030-01Z-00-DX1.5DDF24B5-00D1-4418-A067-A9B609E15314 ...\n",
      "Total number of contours to process:  2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86847/2998935610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                         \u001b[0mstitch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstitch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                                         \u001b[0mpatch_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                                         process_list = process_list, auto_skip=no_auto_skip)\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_86847/3132442489.py\u001b[0m in \u001b[0;36mseg_and_patch\u001b[0;34m(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, patch_size, step_size, seg_params, filter_params, vis_params, patch_params, patch_level, use_default_params, seg, save_mask, stitch, patch, auto_skip, process_list)\u001b[0m\n\u001b[1;32m    201\u001b[0m             current_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n\u001b[1;32m    202\u001b[0m                                         'save_path': patch_save_dir})\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_time_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWSI_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWSI_object\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpatient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_patch_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mstitch_time_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_86847/3132442489.py\u001b[0m in \u001b[0;36mpatching\u001b[0;34m(WSI_object, patient_id, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWSI_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/js.yun/CLAM/wsi_core/WholeSlideImage.py\u001b[0m in \u001b[0;36mprocess_contours\u001b[0;34m(self, patient_id, save_path, patch_level, patch_size, step_size, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing contour {}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_contours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0masset_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_contour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholes_tissue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masset_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared/js.yun/CLAM/wsi_core/WholeSlideImage.py\u001b[0m in \u001b[0;36mprocess_contour\u001b[0;34m(self, cont, contour_holes, patch_level, save_path, patch_size, step_size, contour_fn, use_padding, top_left, bot_right)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mstart_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboundingRect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mpatch_downsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_downsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel_downsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_level\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0mref_patch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_downsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpatch_downsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "source": [
    "# main\n",
    "patch_save_dir = os.path.join(save_dir, 'patches')\n",
    "mask_save_dir = os.path.join(save_dir, 'masks')\n",
    "stitch_save_dir = os.path.join(save_dir, 'stitches')\n",
    "\n",
    "print('source: ', source)\n",
    "print('patch_save_dir: ', patch_save_dir)\n",
    "print('mask_save_dir: ', mask_save_dir)\n",
    "print('stitch_save_dir: ', stitch_save_dir)\n",
    "\n",
    "directories = {'source': source, \n",
    "                'save_dir': save_dir,\n",
    "                'patch_save_dir': patch_save_dir, \n",
    "                'mask_save_dir' : mask_save_dir, \n",
    "                'stitch_save_dir': stitch_save_dir} \n",
    "\n",
    "for key, val in directories.items():\n",
    "    print(\"{} : {}\".format(key, val))\n",
    "    if key not in ['source']:\n",
    "        os.makedirs(val, exist_ok=True)\n",
    "\n",
    "seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "                'keep_ids': 'none', 'exclude_ids': 'none'}\n",
    "filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8}\n",
    "vis_params = {'vis_level': -1, 'line_thickness': 250}\n",
    "patch_params = {'use_padding': True, 'contour_fn': 'four_pt'}\n",
    "\n",
    "parameters = {'seg_params': seg_params,\n",
    "                'filter_params': filter_params,\n",
    "                'patch_params': patch_params,\n",
    "                'vis_params': vis_params}\n",
    "print('\\n', parameters, '\\n')\n",
    "\n",
    "seg_times, patch_times = seg_and_patch(**directories, **parameters,\n",
    "                                        patch_size = patch_size, step_size=step_size, \n",
    "                                        seg = seg,  use_default_params=False, save_mask = True, \n",
    "                                        stitch= stitch,\n",
    "                                        patch_level=patch_level, patch = patch,\n",
    "                                        process_list = process_list, auto_skip=no_auto_skip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_AssociatedImageMap {'thumbnail': <PIL.Image.Image image mode=RGBA size=1024x742 at 0x7F7CEAFC3110>}>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import openslide\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from openslide.lowlevel import *\n",
    "from openslide.lowlevel import _read_region as _read_region\n",
    "from openslide.lowlevel import _convert\n",
    "import io\n",
    "\n",
    "def read_region(self, location, level, size):\n",
    "    \"\"\"Return a PIL.Image containing the contents of the region.\n",
    "\n",
    "    location: (x, y) tuple giving the top left pixel in the level 0\n",
    "                reference frame.\n",
    "    level:    the level number.\n",
    "    size:     (width, height) tuple giving the region size.\n",
    "\n",
    "    Unlike in the C interface, the image data returned by this\n",
    "    function is not premultiplied.\"\"\"\n",
    "    return lowlevel_read_region(\n",
    "        self._osr, location[0], location[1], level, size[0], size[1]\n",
    "    )\n",
    "\n",
    "def lowlevel_read_region(slide, x, y, level, w, h):\n",
    "    if w < 0 or h < 0:\n",
    "        # OpenSlide would catch this, but not before we tried to allocate\n",
    "        # a negative-size buffer\n",
    "        raise OpenSlideError(\n",
    "            \"negative width (%d) or negative height (%d) not allowed\" % (w, h)\n",
    "        )\n",
    "    if w == 0 or h == 0:\n",
    "        # PIL.Image.frombuffer() would raise an exception\n",
    "        return PIL.Image.new('RGBA', (w, h))\n",
    "    buf = (w * h * c_uint32)()\n",
    "    _read_region(slide, buf, x, y, level, w, h)\n",
    "    return load_image_as_numpy_rgb(buf, (w, h))\n",
    "\n",
    "def load_image_as_numpy_rgb(buf, size):\n",
    "    '''buf must be a mutable buffer.'''\n",
    "    arr = torch.frombuffer(buf, dtype=torch.uint8).view(size[1], size[0], 4)\n",
    "    # Select RGB channels, reverse the order, and transpose       이거까지 GPU에서 하는게 나을듯\n",
    "    rgb_arr = arr[..., [2, 1, 0]].permute(2, 0, 1).contiguous()\n",
    "    \n",
    "    # return PIL.Image.frombuffer('RGBA', size, buf, 'raw', 'RGBA', 0, 1)\n",
    "    return rgb_arr\n",
    "\n",
    "\n",
    "\n",
    "slide = openslide.open_slide('/shared/j.jang/pathai/data/TCGA-lung/00a0b174-1eab-446a-ba8c-7c6e3acd7f0c/TCGA-MN-A4N4-01Z-00-DX2.9550732D-8FB1-43D9-B094-7C0CD310E9C0.svs')\n",
    "# print(slide.properties)\n",
    "print(slide.associated_images)\n",
    "\n",
    "\n",
    "\n",
    "# slide.read_region = read_region.__get__(slide)\n",
    "# image_pil = slide.read_region(location=(13000,33000), level=0, size=(256, 256))\n",
    "# print(type(image_pil))\n",
    "\n",
    "\n",
    "# encode_image = torchvision.io.encode_jpeg(image_pil, 75)\n",
    "\n",
    "\n",
    "# # HDF5 파일 생성\n",
    "# file_path_pil = 'encode.hdf5'\n",
    "# if os.path.exists(file_path_pil):\n",
    "#     os.remove(file_path_pil)\n",
    "# # file_path_jpg = 'test_jpg.hdf5'\n",
    "# # if os.path.exists(file_path_jpg):\n",
    "# #     os.remove(file_path_jpg)\n",
    "\n",
    "# with h5py.File(file_path_pil, 'w') as f:\n",
    "#     dset = f.create_dataset('binary_data', data=encode_image)\n",
    "#     f.close()\n",
    "\n",
    "\n",
    "# # HDF5 파일에서 데이터 읽어오기 (바이트로)\n",
    "# with h5py.File(file_path_pil, 'r') as f:\n",
    "#     binary_data = f['binary_data'][()]\n",
    "\n",
    "\n",
    "# # 바이트 데이터를 JPEG로 디코딩하고 텐서로 변환\n",
    "# image_pil_from_bytes = Image.open(io.BytesIO(binary_data))\n",
    "# tensor_from_numpy = torch.from_numpy(binary_data)\n",
    "# image_tensor = torchvision.io.decode_image(tensor_from_numpy)\n",
    "\n",
    "# image_pil_from_bytes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
